# OSG-Bigtop
The following are notes and tools gained in the process of migrating UW-Madison CMS-T2 from OpenScience Grid (3.5) packaged HDFS to Bigtop (1.5.0) packaging.  

## Supplemental RPM
The hdfs-bigtop-osg.rpm should be installed at the same time as Bigtop 1.5.0 RPMs. The hdfs-bigtop-osg.rpm (built from hdfs-bigtop-osg.spec file 'rpmbuild -bb name.specfile') satisfies the OSG RPM dependencies and installs a symlink from /usr/lib64/libhdfs.so.0.0.0 to /usr/lib64/libhdfs.so.0 .  This symlink allows xrootd and globus-gridftp packaged by OSG to run with Hadoop as packaged by Bigtop.

## Migration Notes
In general follow the procedure given by Hadoop, but with the notes below.
We used **HA with downtime** https://hadoop.apache.org/docs/r2.10.1/hadoop-project-dist/hadoop-hdfs/HDFSHighAvailabilityWithQJM.html#HDFS_UpgradeFinalizationRollback_with_HA_Enabled
There is also an **HA without downtime** but the instructions for how to start the namenode daemon a) after starting the upgrade but b) before finishing the upgrade are not clear.  (Using HA with downtime in this scenario the namenode daemon should be started with no special command line switches.)
- After updating the NameNode to Bigtop, you may need to modify /usr/lib/hadoop-hdfs/bin/hdfs line 146 with environmental overrides normally sourced from /etc/default/hadoop-hdfs-namenode.  In our case, we increase the JVM heap size. You'll need to add whatever overrides which appear in /etc/default/hadoop-hdfs-namenode .  That file is sourced in the init script, but when upgrading HDFS the init scripts are not used when starting the namenode daemon. E.g. we changed HADOOP_OPTS="$HADOOP_OPTS $HADOOP_NAMENODE_OPTS" to HADOOP_OPTS="$HADOOP_OPTS $HADOOP_NAMENODE_OPTS -Xmx60000m".
- You may have to restart each (or some) datanodes to get them to connect to the namenodes after namenodes are upgraded and restarted.  Create a list of datanodes before upgrade: 'hdfs dfsadmin -report -live 2>/dev/null | grep Hostname | sed -E 's/^.*\s+//g' > /tmp/datanodes' Be prepared to iterate over this list restarting datanodes.  (We used a script to ssh to each datanode and restart the datanode. If you don't have such a script, let us know.)
- We encountered what appears to be the bug "DN may not send block report to NN after NN restart" https://issues.apache.org/jira/browse/HDFS-12749 . The symptom is that datanodes connect to the namenode, but the namenode "Datanodes" status page shows their block count to be 0 (if HDFS is in safemode). This can be worked around by triggering a block report from each datanode after it connects to the namenode.  The script triggerBlockReportAllDNs.sh automates this either by querying the namenodes for connected datanodes or reading in a list of datanodes.
- Furthermore, we needed to trigger block reports every time we upgraded a datanode or  the namenodes would begin reporting missing and underreplicated blocks.
- Datanodes need more JVM heap to upgrade than they do to run normally.
- Occassionally blocks would show up in the missing list, but could be recovered from the hdfs/current/BP-xxxxxxxxx-IPADDRESS-xxxxxxxxxxxx/previous.tmp directory. Possibly this was due to the datanode running out of Java Heap and terminating in the middle of the it first run.  To recover these blocks, you'll need a way to find the last known location of a block file.  (We have a script for tracing block to node.) One way to rescue that block is to shutdown the datanode daemon, copy the block file and matching meta file out of the previous.tmp directory into the active blocks directory, then restart the datanode (with enough JVM heap!).  E.g. cp /data/04/hdfs/current/BP-xxxxxxxxx-IPADDRESS-xxxxxxxxxxxx/current/finalized/subdir24/subdir9/blk_-4848188265532479052 /data/04/hdfs/current/BP-xxxxxxxxx-IPADDRESS-xxxxxxxxxxxx/current/finalized/subdir24/subdir9/blk_-4848188265532479052
- xrootd, gridftp, and other daemons which use HDFS libraries should be restarted to load the new libraries

